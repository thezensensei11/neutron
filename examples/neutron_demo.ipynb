{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Neutron: Professional Market Data Pipeline\n",
        "\n",
        "Welcome to the **Neutron** comprehensive tutorial. This notebook demonstrates how to build a production-grade market data pipeline capable of downloading, repairing, storing, and analyzing massive datasets from crypto exchanges.\n",
        "\n",
        "## Key Capabilities\n",
        "1.  **Multi-Exchange Support**: Architecture designed for Binance, Bitstamp, Bybit, and more.\n",
        "2.  **Diverse Data Types**: \n",
        "    *   **OHLCV** (Candlesticks)\n",
        "    *   **Trades** (Tick-level data)\n",
        "    *   **Aggregated Trades** (Compressed ticks)\n",
        "    *   **Metrics** (Open Interest, Long/Short Ratios)\n",
        "    *   **Advanced Klines**: Mark Price, Index Price, Premium Index\n",
        "3.  **Smart Gap Repair**: Automatically identify and fill missing data points using smart fallback strategies.\n",
        "4.  **Flexible Storage**: Supports both **PostgreSQL** (for structured querying) and **Parquet** (for high-performance file storage).\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup & Initialization\n",
        "First, we set up the environment and initialize the core components.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "import sys\n",
        "import os\n",
        "import logging\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime, timedelta, timezone\n",
        "\n",
        "# Add src to path\n",
        "sys.path.append('../src')\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "sns.set_theme(style=\"darkgrid\")\n",
        "\n",
        "from neutron.core.downloader import Downloader\n",
        "from neutron.core.crawler import DataCrawler\n",
        "from neutron.core.config import NeutronConfig, StorageConfig, TaskConfig\n",
        "from neutron.services.info_service import InfoService\n",
        "from neutron.services.gap_fill_service import GapFillService\n",
        "\n",
        "print(\"Neutron libraries loaded successfully.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## 2. Configuration: The Blueprint\n",
        "\n",
        "Neutron uses a declarative configuration approach. You define *what* you want, and the system handles *how* to get it.\n",
        "\n",
        "Below is a comprehensive configuration that fetches:\n",
        "*   **Spot Data**: OHLCV and Aggregated Trades for BTC/USDT.\n",
        "*   **Futures Data**: Mark Price, Index Price, Premium Index, and Open Interest Metrics.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Define Configuration\n",
        "config = NeutronConfig(\n",
        "    storage=StorageConfig(type='database'), \n",
        "    data_state_path='data_state.json',\n",
        "    exchange_state_path='exchange_state.json',\n",
        "    max_workers=8, # High parallelism for multiple data types\n",
        "    \n",
        "    tasks=[\n",
        "        # --- SPOT DATA ---\n",
        "        # OHLCV (1 Day - Foundation)\n",
        "        TaskConfig(\n",
        "            type='backfill_ohlcv',\n",
        "            params={'timeframe': '1h', 'start_date': '2024-11-15T00:00:00', 'end_date': '2024-11-16T00:00:00', 'rewrite': True},\n",
        "            exchanges={'binance': {'spot': {'symbols': ['BTC/USDT']}}}\n",
        "        ),\n",
        "        # Aggregated Trades (2 Minutes Sample)\n",
        "        TaskConfig(\n",
        "            type='backfill_agg_trades',\n",
        "            params={'start_date': '2024-11-15T00:00:00', 'end_date': '2024-11-15T00:02:00', 'rewrite': True},\n",
        "            exchanges={'binance': {'spot': {'symbols': ['BTC/USDT']}}}\n",
        "        ),\n",
        "        \n",
        "        # --- FUTURES DATA (UM) ---\n",
        "        # Mark Price Klines (1 Day)\n",
        "        TaskConfig(\n",
        "            type='backfill_mark_price_klines',\n",
        "            params={'timeframe': '1h', 'start_date': '2024-11-15T00:00:00', 'end_date': '2024-11-16T00:00:00', 'rewrite': True},\n",
        "            exchanges={'binance': {'swap': {'symbols': ['BTC/USDT']}}}\n",
        "        ),\n",
        "        # Index Price Klines (1 Day)\n",
        "        TaskConfig(\n",
        "            type='backfill_index_price_klines',\n",
        "            params={'timeframe': '1h', 'start_date': '2024-11-15T00:00:00', 'end_date': '2024-11-16T00:00:00', 'rewrite': True},\n",
        "            exchanges={'binance': {'swap': {'symbols': ['BTC/USDT']}}}\n",
        "        ),\n",
        "        # Premium Index Klines (1 Day)\n",
        "        TaskConfig(\n",
        "            type='backfill_premium_index_klines',\n",
        "            params={'timeframe': '1h', 'start_date': '2024-11-15T00:00:00', 'end_date': '2024-11-16T00:00:00', 'rewrite': True},\n",
        "            exchanges={'binance': {'swap': {'symbols': ['BTC/USDT']}}}\n",
        "        ),\n",
        "        # Metrics (Open Interest) (1 Day)\n",
        "        TaskConfig(\n",
        "            type='backfill_metrics',\n",
        "            params={'start_date': '2024-11-15T00:00:00', 'end_date': '2024-11-16T00:00:00', 'rewrite': True},\n",
        "            exchanges={'binance': {'swap': {'symbols': ['BTC/USDT']}}}\n",
        "        )\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Initialize Downloader with this config\n",
        "downloader = Downloader(config=config)\n",
        "print(\"Downloader initialized with task configuration.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## 3. Execution\n",
        "Run the downloader. The system intelligently manages rate limits and parallelizes non-OHLCV tasks for maximum throughput.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "print(\"ðŸš€ Starting Comprehensive Download...\")\n",
        "# In a real run, you would uncomment the line below:\n",
        "# downloader.run()\n",
        "print(\"âœ… Download Complete (Simulated for demo speed).\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## 4. Data Quality & Gap Detection\n",
        "Data integrity is critical for quantitative analysis. Neutron's `InfoService` provides deep introspection into your datasets.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "info_service = InfoService(downloader.storage)\n",
        "\n",
        "# Generate a summary report\n",
        "# deep_scan=True scans every row to find gaps (slower but accurate)\n",
        "# show_gaps=True lists specific gap ranges\n",
        "print(\"Generating Data Quality Report...\")\n",
        "info_service.generate_summary(deep_scan=True, show_gaps=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## 5. Smart Gap Repair\n",
        "Missing data can crash backtests. The `GapFillService` offers two modes to fix this:\n",
        "\n",
        "*   **`smart` (Default)**: Attempts to download the missing data from the exchange. If the exchange returns no data (and the check is enabled), it can fallback.\n",
        "*   **`zero_fill`**: Forces synthesis of zero-volume candles for the missing range. This is useful for \"maintenance gaps\" where the exchange truly has no data. Synthesized candles are marked with `is_interpolated=True`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# 1. Get the gap report\n",
        "gaps = info_service.get_gap_report()\n",
        "print(f\"Found {len(gaps)} gaps.\")\n",
        "\n",
        "# 2. Initialize Gap Filler\n",
        "gap_filler = GapFillService(downloader)\n",
        "\n",
        "# 3. Fill Gaps (Demonstration)\n",
        "if gaps:\n",
        "    print(f\"Attempting to fill {min(5, len(gaps))} gaps using Zero-Fill mode...\")\n",
        "    subset_gaps = gaps[:5] \n",
        "    stats = gap_filler.fill_gaps(subset_gaps, mode='zero_fill')\n",
        "    print(\"Gap Fill Stats:\", stats)\n",
        "else:\n",
        "    print(\"No gaps to fill - Data is continuous!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## 6. Data Retrieval & Analysis\n",
        "Neutron provides a unified `DataCrawler` interface to access all stored data types as Pandas DataFrames.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "crawler = DataCrawler(storage_type='database')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### A. Price Analysis (Spot vs Mark vs Index)\n",
        "Compare the Spot price against Futures Mark and Index prices to identify divergence or arbitrage opportunities.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Fetch Data\n",
        "df_spot = crawler.get_ohlcv('binance', 'BTC/USDT', '1h', '2024-11-15', '2024-11-16', instrument_type='spot')\n",
        "df_mark = crawler.get_mark_price_klines('binance', 'BTC/USDT', '1h', '2024-11-15', '2024-11-16', instrument_type='swap')\n",
        "df_index = crawler.get_index_price_klines('binance', 'BTC/USDT', '1h', '2024-11-15', '2024-11-16', instrument_type='swap')\n",
        "\n",
        "# Plot\n",
        "if not df_spot.empty and not df_mark.empty:\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(df_spot['time'], df_spot['close'], label='Spot Close', alpha=0.7)\n",
        "    plt.plot(df_mark['time'], df_mark['close'], label='Mark Price', linestyle='--')\n",
        "    if not df_index.empty:\n",
        "        plt.plot(df_index['time'], df_index['close'], label='Index Price', linestyle=':')\n",
        "        \n",
        "    plt.title('BTC/USDT: Spot vs Mark vs Index Price')\n",
        "    plt.xlabel('Time')\n",
        "    plt.ylabel('Price (USDT)')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Data not available for plotting.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### B. Premium Index Analysis\n",
        "The Premium Index indicates the funding rate direction. Positive values imply Longs pay Shorts.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "df_premium = crawler.get_premium_index_klines('binance', 'BTC/USDT', '1h', '2024-11-15', '2024-11-16', instrument_type='swap')\n",
        "\n",
        "if not df_premium.empty:\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.plot(df_premium['time'], df_premium['close'], color='purple', label='Premium Index')\n",
        "    plt.axhline(0, color='black', linewidth=0.8)\n",
        "    plt.title('BTC/USDT Premium Index')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### C. Market Metrics (Open Interest)\n",
        "Analyze Open Interest trends to gauge market sentiment and liquidity.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "df_metrics = crawler.get_metrics('binance', 'BTC/USDT', '2024-11-15', '2024-11-16', instrument_type='swap')\n",
        "\n",
        "if not df_metrics.empty:\n",
        "    # Metrics data often comes in 5m intervals, let's resample to 1h for clarity\n",
        "    df_metrics.set_index('create_time', inplace=True)\n",
        "    df_resampled = df_metrics.resample('1h').last()\n",
        "    \n",
        "    plt.figure(figsize=(12, 6))\n",
        "    sns.lineplot(data=df_resampled, x=df_resampled.index, y='sum_open_interest', label='Open Interest (Contracts)')\n",
        "    plt.title('BTC/USDT Open Interest')\n",
        "    plt.ylabel('Open Interest')\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## 7. HFT & Microstructure Analysis\n",
        "Neutron allows you to dive deep into tick-level data. In this section, we analyze `aggTrades` to understand market microstructure.\n",
        "\n",
        "**Key Metrics:**\n",
        "*   **Trade Flow Imbalance (CVD)**: Cumulative Volume Delta to see aggressive buying vs selling.\n",
        "*   **VWAP**: Volume Weighted Average Price, a benchmark for institutional execution.\n",
        "*   **Inter-arrival Times**: How fast are trades hitting the matching engine?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "crawler = DataCrawler(storage_type='database')\n",
        "\n",
        "\n",
        "# 1. Fetch Aggregated Trades (1 Hour Slice)\n",
        "print(\"Fetching AggTrades for Microstructure Analysis...\")\n",
        "df_trades = crawler.get_data(\n",
        "    data_type='aggTrades', \n",
        "    exchange='binance', \n",
        "    symbol='BTC/USDT', \n",
        "    start_date='2024-11-15T00:00:00', \n",
        "    end_date='2024-11-15T01:00:00', \n",
        "    instrument_type='spot'\n",
        ")\n",
        "\n",
        "if not df_trades.empty:\n",
        "    print(f\"Loaded {len(df_trades)} trades.\")\n",
        "    \n",
        "    # 2. Preprocessing\n",
        "    # Binance 'is_buyer_maker' = True -> Taker was Seller (SELL)\n",
        "    # Binance 'is_buyer_maker' = False -> Taker was Buyer (BUY)\n",
        "    df_trades['side'] = df_trades['is_buyer_maker'].apply(lambda x: 'sell' if x else 'buy')\n",
        "    df_trades['signed_qty'] = df_trades.apply(lambda x: x['qty'] if x['side'] == 'buy' else -x['qty'], axis=1)\n",
        "    df_trades['cost'] = df_trades['price'] * df_trades['qty']\n",
        "    \n",
        "    # 3. Cumulative Volume Delta (CVD)\n",
        "    df_trades['cvd'] = df_trades['signed_qty'].cumsum()\n",
        "    \n",
        "    # 4. VWAP Calculation\n",
        "    df_trades['cum_cost'] = df_trades['cost'].cumsum()\n",
        "    df_trades['cum_qty'] = df_trades['qty'].cumsum()\n",
        "    df_trades['vwap'] = df_trades['cum_cost'] / df_trades['cum_qty']\n",
        "    \n",
        "    # Visualization: Price vs VWAP vs CVD\n",
        "    fig, ax1 = plt.subplots(figsize=(14, 8))\n",
        "    \n",
        "    color = 'tab:blue'\n",
        "    ax1.set_xlabel('Time')\n",
        "    ax1.set_ylabel('Price', color=color)\n",
        "    ax1.plot(df_trades['time'], df_trades['price'], label='Price', color=color, alpha=0.3)\n",
        "    ax1.plot(df_trades['time'], df_trades['vwap'], label='VWAP', color='orange', linestyle='--')\n",
        "    ax1.tick_params(axis='y', labelcolor=color)\n",
        "    ax1.legend(loc='upper left')\n",
        "    \n",
        "    ax2 = ax1.twinx()  \n",
        "    color = 'tab:green'\n",
        "    ax2.set_ylabel('Cumulative Volume Delta (BTC)', color=color)\n",
        "    ax2.plot(df_trades['time'], df_trades['cvd'], label='CVD', color=color, alpha=0.7)\n",
        "    ax2.tick_params(axis='y', labelcolor=color)\n",
        "    ax2.legend(loc='upper right')\n",
        "    \n",
        "    plt.title('BTC/USDT Microstructure: Price, VWAP, and Order Flow Imbalance')\n",
        "    plt.show()\n",
        "    \n",
        "else:\n",
        "    print(\"No aggTrades data found. Did you run the backfill?\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# 5. Inter-arrival Times (Latency Analysis)\n",
        "if not df_trades.empty:\n",
        "    # Ensure sorted by time\n",
        "    df_trades = df_trades.sort_values('time')\n",
        "    \n",
        "    # Calculate time difference in milliseconds\n",
        "    df_trades['inter_arrival_ms'] = df_trades['time'].diff().dt.total_seconds() * 1000\n",
        "    \n",
        "    # Filter valid differences (drop first NaN)\n",
        "    inter_arrivals = df_trades['inter_arrival_ms'].dropna()\n",
        "    \n",
        "    if not inter_arrivals.empty:\n",
        "        print(f\"Inter-arrival Stats (ms):\\n{inter_arrivals.describe()}\")\n",
        "        \n",
        "        plt.figure(figsize=(12, 5))\n",
        "        \n",
        "        # Use a robust histogram with auto-binning\n",
        "        sns.histplot(inter_arrivals, bins=50, log_scale=(False, True), kde=False)\n",
        "        \n",
        "        plt.title('Trade Inter-arrival Time Distribution (Log Scale Y)')\n",
        "        plt.xlabel('Milliseconds between trades')\n",
        "        plt.ylabel('Count')\n",
        "        \n",
        "        # Dynamic x-limit based on 99th percentile to ignore outliers\n",
        "        p99 = inter_arrivals.quantile(0.99)\n",
        "        if p99 > 0:\n",
        "            plt.xlim(0, p99 * 1.1)\n",
        "            \n",
        "        plt.show()\n",
        "        \n",
        "        print(f\"Median Inter-arrival Time: {inter_arrivals.median():.2f} ms\")\n",
        "        print(f\"Zero-latency trades (same timestamp): {(inter_arrivals == 0).sum()} / {len(inter_arrivals)}\")\n",
        "    else:\n",
        "        print(\"Not enough data to calculate inter-arrival times.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# 6. High-Resolution Resampling (100ms Bars)\n",
        "if not df_trades.empty:\n",
        "    print(\"Resampling to 100ms bars to capture micro-volatility...\")\n",
        "    df_resampled = df_trades.set_index('time').resample('100ms').agg({\n",
        "        'price': ['first', 'max', 'min', 'last'],\n",
        "        'qty': 'sum'\n",
        "    })\n",
        "    df_resampled.columns = ['open', 'high', 'low', 'close', 'volume']\n",
        "    df_resampled.dropna(inplace=True)\n",
        "    \n",
        "    # Calculate Micro-Volatility (High - Low)\n",
        "    df_resampled['volatility'] = df_resampled['high'] - df_resampled['low']\n",
        "    \n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.plot(df_resampled.index, df_resampled['volatility'], color='red', alpha=0.6)\n",
        "    plt.title('Micro-Volatility (100ms High-Low Spread)')\n",
        "    plt.ylabel('Price Spread (USDT)')\n",
        "    plt.show()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
